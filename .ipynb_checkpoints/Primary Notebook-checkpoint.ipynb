{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f421493",
   "metadata": {},
   "source": [
    "# Team Viviane Solomon and Brandon Bonifacio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af2f975",
   "metadata": {},
   "source": [
    "# HW6: Life Cycle of ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e4cace",
   "metadata": {},
   "source": [
    "Your goal is to develop a CNN model that, given a cell phone image\n",
    "taken somewhere inside a building on HMC campus, can identify which building is being\n",
    "photographed. You may use any online resources that you find helpful, but you must cite your\n",
    "sources and indicate clearly what portions of your code have been copied and modified from\n",
    "elsewhere. You may work individually or with a partner on this assignment. Please submit your\n",
    "assignment as a single jupyter notebook on Sakai. If you work with a partner, make sure to\n",
    "indicate both partners’ names clearly at the very top of your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a6e741",
   "metadata": {},
   "source": [
    "## Part 1: Data Collection/Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e61c7f3",
   "metadata": {},
   "source": [
    "In the first part of the assignment, you will do the following:\n",
    "\n",
    "\n",
    "• Data Collection (15 points). Each student/team will collect 50 cell phone pictures taken\n",
    "of random locations inside a single building on campus. Please sign up for a building to\n",
    "photograph in this spreadsheet, and upload your pictures to this shared google drive.\n",
    "Since the data will be used by the entire class, please complete this portion of the\n",
    "assignment by Saturday 1pm (-5 points if not done by then). If there are more than 5\n",
    "buildings represented in the class data, you may simply select 5 buildings to use for this\n",
    "assignment.\n",
    "\n",
    "\n",
    "• Data Preparation (15 points). Download the class data onto your laptop. Prepare the\n",
    "data for use in PyTorch by ensuring image format compatibility, putting the images in a\n",
    "suitable directory structure, and creating train & validation partitions. Describe your\n",
    "data preparation process in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a75ed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Statements\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd746b1",
   "metadata": {},
   "source": [
    "### In the cells below, we prepare the data for use in PyTorch by ensuring image format compatiblity, putting the images in a suitable directory structure, and creating train & validation partitions. We describe our data preparation process in the markdown cell below, and then encode it after that. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc92a79",
   "metadata": {},
   "source": [
    "***Input description here***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0fea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prepare_data():\n",
    "    \"\"\"\n",
    "    This function loads and partitions our image data.\n",
    "    \"\"\"\n",
    "    #EXAMPLE MNIST CODE:\n",
    "    mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "    X_train = np.array(mnist_trainset.data.reshape(len(mnist_trainset), -1), dtype = np.float64)/255\n",
    "    Y_train = pd.get_dummies(np.array(mnist_trainset.targets)).to_numpy(dtype = np.float64) # one-hot encoding\n",
    "\n",
    "    mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=None)\n",
    "    X_test = np.array(mnist_testset.data.reshape(len(mnist_testset), -1), dtype = np.float64)/255\n",
    "    Y_test = pd.get_dummies(np.array(mnist_testset.targets)).to_numpy(dtype = np.float64)\n",
    "    \n",
    "    \n",
    "    #We should also try some data augmentation methods - simple stuff like adding random noise (there's packages for that)\n",
    "    \n",
    "    return return X_train, Y_train, X_val, Y_val, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db76f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = load_prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2017bb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img = X_train[0,:].reshape((28,28))\n",
    "plt.imshow(sample_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3d42cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3debb6b3",
   "metadata": {},
   "source": [
    "## Part 2: Nearest Neighbors Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399f61a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda9206a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659b5280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
